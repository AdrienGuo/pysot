### 07/15/2022
這個禮拜都在處理會遇到 target 變很多個的問題，因為原本的 target 只會有一個(追蹤任務)，但我現在變很多個(偵測任務)，所以就多了一個維度；但其實最麻煩的問題是，原本只有一個 target 的情況，所有的 anchors 在算類別和迴歸的差異的時候，就全部都去跟唯一的那個 target 算就好了，可是我現在不行，我有很多個 targets，所以每一個 anchor 要去跟 **"哪一個"** target 去算類別和迴歸的差異就要去找，最後我是用將每一個 anchor 和每一個 target 都去算 iou，然後選和該 anchor 有最大 iou 的那個 target 就是要互相去計算的一個 pair  
演算法的部分寫在 bbox.py 的 def target_overlaps() 裡面。方法其實就很基礎，跑兩層 for 迴圈，然後會得到每一個 anchor 和每一個 target 的 iou 的矩陣 [N(anchor), K(target)]，然後用 argmax 就可以得到和每個 anchor iou 最大的那個 target，之後再把這個東東放去 def target_delta() 裡面去計算 delta(迴歸)。  
以上就是這個禮拜處理的東西 (應該花了有 3,4天😥)，主要是因為多維的矩陣讓我很難確定是好好對齊維度的 qq。

### 07/16/2022
成功讀到資料了，真感動，雖然裡面的 bbox 和 圖片大小都還是錯的 哀，但至少把多個 targets 的問題處理好了，可是不知道後面還會有多少問題...，現在又遇到一個神奇的問題，`RuntimeError: Trying to resize storage that is not resizable` ，但現在是 02:37，有夠晚，可是仲瑜也還在線上!! 但我要去睡了 嗚嗚。  
上面的問題我先把 num_worker 設為 0，就 "暫時" 沒事了，但這是假象，因為會報錯的原因是有些 annotations 是空的，導致沒辦法 iter。  
- `RuntimeError: stack expects each tensor to be equal size, but got [4, 1] at entry 0 and [4, 2] at entry 2`  
然後我又遇到類似的 bug，因為 target 的數量不一樣導致的...；問了亭儀後，我其實馬上就找到方法，要在 dataset 裡面多加一個 def collate_fn()，用不同的方法傳資料 (真的超麻煩)
- AttributeError: 'list' object has no attribute 'cuda'  
把裡面的每個元素都 .cuda()

我發現想要把所有遇到的問題都記下來真的太麻煩了，而且應該很難遇到一樣的情況，頂多類似，類似的話應該也可以想起來之前是怎麼做的，就像解數學題目一樣的感覺，反正今天終於成功讓他跑起來了。  
然後發現 phew 一下就跑完了，原來它竟然只有跑一個 epoch，應該是因為原本是使用了 4個資料集，已經超級大了，這個地方需要改一下。  

不過現在最重要的是切 template, search 的方式不太對，要先弄這部分，希望其他部分不要有太大的問題，拜託~~。  

### 07/17/2022
整天都在對資料有沒有標籤錯誤，也是遇到一堆奇怪問題，像是 cv2 讀進來的資料是 BGR，用 cv2 畫圖的座標一定要整數，bbox 一下子是比例，一下是 corner 又或是 center，反正一堆神奇的問題，但我真的覺得在一開始如果都寫清楚 訂好的話，就不會一堆我看不懂的問題了，不然至少寫一個註解吧...；但其實現在裡面怎麼切割圖片和放大縮小的我完全沒看，因為真的太醜了，而且不知道它的原理慢慢理解超級花時間，現在雖然程式跑起來了，但是還有很多問題要解決，loss 降不下來, 負樣本還沒給, nms, k-means 找 anchor，有夠多的拉。  

晚上在處理 test 的部分，我拿我的模型效果真的頗差，但是用官方的權重檔，效果變超好!! 真的是滿厲害的ㄟ，看來接下來要把 train 的部分搞定了，像是加入 neg (負樣本) 之類的，我也不確定他們要怎麼用 其實...。  

### 07/18/2022
- 處理拿 neg 會遇到 anchor 的問題 (我改成任意選擇一個當作 target)。
- 用單一目標的情況，loss 變超低，可是我自己寫的多目標追蹤 loss 很高，所以應該就是我那裏寫的有問題。

晚上正式讓多目標的也正常跑起來了!! 好感動，結果之前錯的原因是因為我 IoU 算錯，我的算法讓沒有交集的也會有 iou (因為我取距離後的絕對值)，總之就是全錯的，後來改成原版的算法後就整個正常了...，我也是對自己傻眼，竟然錯在這個地方，寫程式就是這樣吧，不每個地方都小心檢查永遠都不知道自己錯在哪裡!!。  

### 07/24/2022
今天整天在搞資料集，剛開始花太多時間在弄論文使用的資料集了，他的和我的方法真的差滿多，所以其實不太需要去參考她的做法，不過還是簡單介紹，  
我是用 coco 當作測試，在一開始的 par_crop.py 裡面，就已經對圖片做處理了，他將拿到的 train 影像，做了一些隨機裁切，具體怎麼做我不是很想看懂了，但反正最重要的是，在這裡的所有 search 的中心點的 127x127 的範圍，都是 template，這點超重要，因為在他的 dataset.py 裡面，就已經全部把 search 的中心當作是 template 的中心了，一開始看就覺得莫名其妙，為甚麼 template 一定是在影像的中心阿?? (話說這樣也頗賤，直接在一開始就偷做處理，不過好處就是以後跑程式就都不用在執行這個，速度會變快，或許我也可以考慮🤔)。  之後 dataset.py 還有是把 search 做論文裡面有提到的 shift 動作，讓 search 裡面的 template 不會都一定是在中心點了，這裡我也沒深入理解 code 的具體怎麼實作，因為我的題目應該用不到，我有很多個 target，所以本來就會平均散佈在 search 的影像中了。  

今天把 template crop 的部分完成，我現在先設定成沒有背景的情況 (我自己也覺得比較合理)，把 template 根據長邊進行縮放，然後再移動到 127x127 template 的中心，其餘部分 padding 成黑色，之後還想加一個參數可以調整要加入的背景範圍多寡。  

### 07/25/2022

